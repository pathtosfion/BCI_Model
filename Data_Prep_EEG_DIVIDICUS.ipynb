{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM9On33APJNT1j4qsWwBRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathtosfion/BCI_Model/blob/main/Data_Prep_EEG_DIVIDICUS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This notegook preforms the following:**\n",
        "\n",
        "\n",
        "- *Loads the CSV file into a pandas DataFrame.*\n",
        "\n",
        "- *Drops the*  **'other_vote'** *column.*\n",
        "\n",
        "- *Drops rows where* **'other'** *is the expert consensus.*\n",
        "\n",
        "- *Defines a function* **'calculate_trust_score`** *to calculate the trust score for each* expert's vote.\n",
        "- *Applies this function to the DataFrame to create a new* **'trust_level'** *column.*\n",
        "- *Drops rows where* **'other'** *is the expert consensus.*\n",
        "- *Drops the* 'expert_consensus' *and vote columns as they are no longer needed.*\n",
        "- *Saves the processed DataFrame to a new CSV file.*\n",
        "\n",
        "### **Please ensure that the CSV file is in the same directory as your Jupyter notebook or provide the correct path to the file. Also, adjust the column names and vote categories as needed for your specific dataset.**"
      ],
      "metadata": {
        "id": "DlqFEb4yS06J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSZ0pOZsSpHH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the CSV file**\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "N5s4mvRLS2ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "1mf2M8zySzjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Display the first few rows of the DataFrame to understand the data structure**"
      ],
      "metadata": {
        "id": "X-OK6AxlS3WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "PiobmYCJSzm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drop the** *'other_vote'* **column**"
      ],
      "metadata": {
        "id": "lRLTRpEOS4b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('other_vote', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "G9vSksdJSzqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drop rows where** *'other'* **is the expert consensus**"
      ],
      "metadata": {
        "id": "6fxAsb04mro7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['expert_consensus'].str.lower() != 'other']"
      ],
      "metadata": {
        "id": "5V1lk1O7mqp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**Define the expert categories**\n",
        " - *and their corresponding vote columns*"
      ],
      "metadata": {
        "id": "CYVRHr8BhOOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expert_categories = ['seizure', 'lpd', 'irpd', 'grda', 'gpd']\n",
        "vote_columns = [f'{expert}_vote' for expert in expert_categories]"
      ],
      "metadata": {
        "id": "4I_QQXNminVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **To express the trust level per row based on the expert consensus and the corresponding vote counts, we can assign weights to each expert's vote based on the number of votes they have. Then, we can sum these weighted votes to get a trust score for each row. Rows where 'other' is the expert consensus can be dropped as they are not needed for the trust level calculation.**"
      ],
      "metadata": {
        "id": "Titigovb0Htf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Function to calculate the trust score**\n",
        "- *for each expert's vote*"
      ],
      "metadata": {
        "id": "7oovg3fei3Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_trust_score(row, expert):\n",
        "    vote_count = row[f'{expert}_vote']\n",
        "    # Normalize the vote count to a range of 0 to 1\n",
        "    normalized_vote = vote_count / 19 if vote_count > 0 else 0\n",
        "    # Apply a weight based on the number of votes\n",
        "    weight = np.log(vote_count + 1)  # Adding 1 to avoid log(0)\n",
        "    return normalized_vote * weight\n"
      ],
      "metadata": {
        "id": "PljIfif0hL15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Calculate the trust score for each expert's vote**\n",
        "- *and sum them to get the total trust level*"
      ],
      "metadata": {
        "id": "cLMVzVzTiXp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['trust_level'] = df.apply(lambda row: sum(calculate_trust_score(row, expert) for expert in expert_categories), axis=1)"
      ],
      "metadata": {
        "id": "OaR-1yHjmC7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drop the expert_consensus and vote columns**\n",
        " - *as they are no longer needed*\n"
      ],
      "metadata": {
        "id": "IhCag5PBS5BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['expert_consensus'] + vote_columns\n",
        "df.drop(columns_to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "lVEEMJwASz2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Display the processed DataFrame**"
      ],
      "metadata": {
        "id": "aJ-dUsAloShV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "289R2HH6UDA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the processed data to a new CSV file**"
      ],
      "metadata": {
        "id": "5YgfH7zYoTbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('processed_train.csv', index=False)"
      ],
      "metadata": {
        "id": "CeqZWZdYUDKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}